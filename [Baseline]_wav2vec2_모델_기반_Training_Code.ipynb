{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssuxmin/tmp/blob/main/%5BBaseline%5D_wav2vec2_%EB%AA%A8%EB%8D%B8_%EA%B8%B0%EB%B0%98_Training_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "k7eulrgaQwYy",
      "metadata": {
        "id": "k7eulrgaQwYy"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rBvX-8P2QwYy",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-07-11T08:41:57.003103Z",
          "start_time": "2022-07-11T08:41:53.892893Z"
        },
        "id": "rBvX-8P2QwYy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm.auto import tqdm\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from transformers import AutoModelForAudioClassification, Wav2Vec2FeatureExtractor\n",
        "\n",
        "warnings.filterwarnings(action='ignore')\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62923ef4",
      "metadata": {
        "id": "62923ef4"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kkqHli22QwYy",
      "metadata": {
        "id": "kkqHli22QwYy"
      },
      "source": [
        "## Hyperparameter Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VtG9mP3RQwYz",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-07-11T08:41:57.006108Z",
          "start_time": "2022-07-11T08:41:57.004370Z"
        },
        "id": "VtG9mP3RQwYz"
      },
      "outputs": [],
      "source": [
        "CFG = {\n",
        "    'SR':16_000,\n",
        "    'SEED':42,\n",
        "    'BATCH_SIZE':8, # out of Memory가 발생하면 줄여주세요\n",
        "    'TOTAL_BATCH_SIZE':32, # 원하는 batch size\n",
        "    'EPOCHS':1,\n",
        "    'LR':1e-4,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f594ad49",
      "metadata": {
        "id": "f594ad49"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"facebook/wav2vec2-base\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QT7_IBn9QwYz",
      "metadata": {
        "id": "QT7_IBn9QwYz"
      },
      "source": [
        "## Fixed Random-Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KgyHxME7QwYz",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-07-11T08:41:57.009050Z",
          "start_time": "2022-07-11T08:41:57.006949Z"
        },
        "id": "KgyHxME7QwYz"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(CFG['SEED']) # Seed 고정"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "r-3_zmrwQwYz",
      "metadata": {
        "id": "r-3_zmrwQwYz"
      },
      "source": [
        "## Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BcxV618ZQwYz",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-07-11T08:41:57.006108Z",
          "start_time": "2022-07-11T08:41:57.004370Z"
        },
        "id": "BcxV618ZQwYz"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('./train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51b9bb53",
      "metadata": {
        "id": "51b9bb53"
      },
      "outputs": [],
      "source": [
        "train_df, valid_df = train_test_split(train_df, test_size=0.2, random_state=CFG['SEED'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e803fb6c",
      "metadata": {
        "id": "e803fb6c"
      },
      "outputs": [],
      "source": [
        "train_df.reset_index(drop=True, inplace=True)\n",
        "valid_df.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5798032a",
      "metadata": {
        "id": "5798032a"
      },
      "outputs": [],
      "source": [
        "def speech_file_to_array_fn(df):\n",
        "    feature = []\n",
        "    for path in tqdm(df['path']):\n",
        "        speech_array, _ = librosa.load(path, sr=CFG['SR'])\n",
        "        feature.append(speech_array)\n",
        "    return feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xUBnp4ciQwYz",
      "metadata": {
        "id": "xUBnp4ciQwYz"
      },
      "outputs": [],
      "source": [
        "train_x = speech_file_to_array_fn(train_df)\n",
        "valid_x = speech_file_to_array_fn(valid_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b9fe61b",
      "metadata": {
        "id": "7b9fe61b"
      },
      "outputs": [],
      "source": [
        "processor = Wav2Vec2FeatureExtractor.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d4e081d",
      "metadata": {
        "id": "2d4e081d"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b14c17a",
      "metadata": {
        "id": "8b14c17a"
      },
      "outputs": [],
      "source": [
        "class CustomDataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, x, y, processor):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.processor = processor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_values = self.processor(self.x[idx], sampling_rate=CFG['SR'], return_tensors=\"pt\", padding=True).input_values\n",
        "        if self.y is not None:\n",
        "            return input_values.squeeze(), self.y[idx]\n",
        "        else:\n",
        "            return input_values.squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0d556ad",
      "metadata": {
        "id": "d0d556ad"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    x, y = zip(*batch)\n",
        "    x = pad_sequence([torch.tensor(xi) for xi in x], batch_first=True)\n",
        "    y = pad_sequence([torch.tensor([yi]) for yi in y], batch_first=True)  # Convert scalar targets to 1D tensors\n",
        "    return x, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48ed6140",
      "metadata": {
        "id": "48ed6140"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(dataset, batch_size, shuffle, collate_fn, num_workers=0):\n",
        "    return DataLoader(dataset,\n",
        "                      batch_size=batch_size,\n",
        "                      shuffle=shuffle,\n",
        "                      collate_fn=collate_fn,\n",
        "                      num_workers=num_workers\n",
        "                      )\n",
        "\n",
        "train_dataset = CustomDataSet(train_x, train_df['label'], processor)\n",
        "valid_dataset = CustomDataSet(valid_x, valid_df['label'], processor)\n",
        "\n",
        "train_loader = create_data_loader(train_dataset, CFG['BATCH_SIZE'], False, collate_fn, 16)\n",
        "valid_loader = create_data_loader(valid_dataset, CFG['BATCH_SIZE'], False, collate_fn, 16)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZC7hzMtOQwY0",
      "metadata": {
        "id": "ZC7hzMtOQwY0"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b4eb920",
      "metadata": {
        "id": "8b4eb920"
      },
      "outputs": [],
      "source": [
        "audio_model = AutoModelForAudioClassification.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49506934",
      "metadata": {
        "id": "49506934"
      },
      "outputs": [],
      "source": [
        "class BaseModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaseModel, self).__init__()\n",
        "        self.model = audio_model\n",
        "        self.model.classifier = nn.Identity()\n",
        "        self.classifier = nn.Linear(256, 8)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.model(x)\n",
        "        output = self.classifier(output.logits)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c3081e9",
      "metadata": {
        "id": "8c3081e9"
      },
      "outputs": [],
      "source": [
        "def validation(model, valid_loader, creterion):\n",
        "    model.eval()\n",
        "    val_loss = []\n",
        "\n",
        "    total, correct = 0, 0\n",
        "    test_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in tqdm(iter(valid_loader)):\n",
        "            x = x.to(device)\n",
        "            y = y.flatten().to(device)\n",
        "\n",
        "            output = model(x)\n",
        "            loss = creterion(output, y)\n",
        "\n",
        "            val_loss.append(loss.item())\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            total += y.size(0)\n",
        "            correct += predicted.eq(y).cpu().sum()\n",
        "\n",
        "    accuracy = correct / total\n",
        "\n",
        "    avg_loss = np.mean(val_loss)\n",
        "\n",
        "    return avg_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aX-3v6JrpX6",
      "metadata": {
        "id": "1aX-3v6JrpX6"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, valid_loader, optimizer, scheduler):\n",
        "    accumulation_step = int(CFG['TOTAL_BATCH_SIZE'] / CFG['BATCH_SIZE'])\n",
        "    model.to(device)\n",
        "    creterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "    best_model = None\n",
        "    best_acc = 0\n",
        "\n",
        "    for epoch in range(1, CFG['EPOCHS']+1):\n",
        "        train_loss = []\n",
        "        model.train()\n",
        "        for i, (x, y) in enumerate(tqdm(train_loader)):\n",
        "            x = x.to(device)\n",
        "            y = y.flatten().to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            output = model(x)\n",
        "            loss = creterion(output, y)\n",
        "            loss.backward()\n",
        "\n",
        "            if (i+1) % accumulation_step == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            train_loss.append(loss.item())\n",
        "\n",
        "        avg_loss = np.mean(train_loss)\n",
        "        valid_loss, valid_acc = validation(model, valid_loader, creterion)\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step(valid_acc)\n",
        "\n",
        "        if valid_acc > best_acc:\n",
        "            best_acc = valid_acc\n",
        "            best_model = model\n",
        "\n",
        "        print(f'epoch:[{epoch}] train loss:[{avg_loss:.5f}] valid_loss:[{valid_loss:.5f}] valid_acc:[{valid_acc:.5f}]')\n",
        "    \n",
        "    print(f'best_acc:{best_acc:.5f}')\n",
        "\n",
        "    return best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c33dd8ed",
      "metadata": {
        "id": "c33dd8ed"
      },
      "source": [
        "## Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14ea3f7b",
      "metadata": {
        "id": "14ea3f7b"
      },
      "outputs": [],
      "source": [
        "model = BaseModel()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=CFG['LR'])\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)\n",
        "\n",
        "infer_model = train(model, train_loader, valid_loader, optimizer, scheduler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Uj-WTX6oQwY0",
      "metadata": {
        "id": "Uj-WTX6oQwY0"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7682a35e",
      "metadata": {
        "id": "7682a35e"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv('./test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d6dac72",
      "metadata": {
        "id": "2d6dac72"
      },
      "outputs": [],
      "source": [
        "def collate_fn_test(batch):\n",
        "    x = pad_sequence([torch.tensor(xi) for xi in batch], batch_first=True)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd93b96f",
      "metadata": {
        "id": "bd93b96f"
      },
      "outputs": [],
      "source": [
        "test_x = speech_file_to_array_fn(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ENCOoU00QwY0",
      "metadata": {
        "id": "ENCOoU00QwY0"
      },
      "outputs": [],
      "source": [
        "test_dataset = CustomDataSet(test_x, y=None, processor=processor)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, collate_fn=collate_fn_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "738067b9",
      "metadata": {
        "id": "738067b9"
      },
      "outputs": [],
      "source": [
        "def inference(model, test_loader):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x in tqdm(iter(test_loader)):\n",
        "            x = x.to(device)\n",
        "\n",
        "            output = model(x)\n",
        "\n",
        "            preds += output.argmax(-1).detach().cpu().numpy().tolist()\n",
        "\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf21ca7d",
      "metadata": {
        "id": "cf21ca7d"
      },
      "outputs": [],
      "source": [
        "preds = inference(infer_model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5FMPeTISQwY0",
      "metadata": {
        "id": "5FMPeTISQwY0"
      },
      "source": [
        "## Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AXO-EmaQQwY0",
      "metadata": {
        "id": "AXO-EmaQQwY0"
      },
      "outputs": [],
      "source": [
        "submission = pd.read_csv('./sample_submission.csv')\n",
        "submission['label'] = preds\n",
        "submission.to_csv('./baseline_submission.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}